# Note
```
guid: GAh@=sDobz
notetype: AI-Vocabulary-Style
```

### Tags
```
```

## Front
ネガティブサンプリング

## Back-EN
Negative sampling

## Back-FR
Échantillonnage négatif

## Reading


## Sentence
モデルは正例（正しい答え）か負例（誤った答え）かで学習しますが、コーパスが大きくなると負例の数も膨大になる（＝計算コストが高くつく）ため、負例は少数を確率的にサンプリングします。これをネガティブサンプリングといい、そのサンプリングに用いる単語数を設定できます。通常は5-20の間とのことですが、大きくすると当然学習にかかる時間は長くなります。コーパスが大きい場合は少なくても良いそう。
