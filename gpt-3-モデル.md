# Note
```
guid: gkXR/]Q/Pw
notetype: AI-Vocabulary-Style
```

### Tags
```
```

## Front
GPT-3 モデル

## Back-EN
GPT-3 model (Generative Pretrained Transformer)

## Back-FR
Modèle GPT-3 (transformer génératif pré-entraîné)

## Reading
GPT-3 モデル

## Sentence
GPT-2の後継モデルである GPT-3 は、教師なしの Transformer 言語モデルである。 GPT-3 は 2020 年 5 月に初めて紹介された。 OpenAI によると、GPT-3 には 1,750 億個のパラメータが含まれ、GPT-2（パラメータ数 15 億個）より 2 桁大きい。
